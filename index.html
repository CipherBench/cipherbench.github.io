<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>CipherBench v2</title>
  <style>
    body {
      background-color: #1e1e1e;
      color: #f5f5f5;
      font-family: system-ui, sans-serif;
      line-height: 1.6;
      max-width: 800px;
      margin: 2rem auto;
      padding: 0 1rem;
    }
     .wrap {
       word-break: break-all;
       overflow-wrap: break-word;
       white-space: normal;
     }
     pre.custom-font {
       font-family: inherit;
       white-space: pre;
       margin: 0;
     }
    h1, h2, h3 {
      margin-top: 2.5rem;
      line-height: 1.3;
    }
    img {
      max-width: 100%;
      margin: 1rem 0;
      border-radius: 4px;
    }
    hr {
      margin: 3rem 0;
      border: none;
      border-top: 1px solid #444;
    }
    ul {
      padding-left: 1.25rem;
    }
    blockquote {
      font-style: italic;
      margin: 1.5rem 0;
      padding-left: 1rem;
      border-left: 3px solid #888;
    }
    .footer {
      text-align: center;
      margin-top: 4rem;
      font-size: 0.95rem;
      color: #aaa;
    }
    .footer em {
      display: block;
      margin-top: 0.5rem;
      font-style: italic;
    }
    .centered {
      text-align: center;
    }
    section {
      margin-bottom: 2rem;
    }
  </style>
</head>
<body>
  <h1 class="centered">CipherBench v2</h1>
  <p class="centered"><a href="https://x.com/SmokeAwayyy" style="color:#ddd; text-decoration: none;">@SmokeAwayyy</a></p>

  <img src="file-WKxQjTZCoM7XAKGCpCe2Pw~3.jpg" alt="Main Bar Chart">

  <section>
    <p>Introducing CipherBench v2</p>
    <p>20 prompts to test implicit reasoning.</p>
    <p>No instructions. Just ciphers.</p>
    <hr>
    <h2>About the Benchmark</h2>
    <p>CipherBench v2 continues the original goal of testing whether language models can recognize and solve hidden patterns without being told what to do. Where most benchmarks evaluate how well a model follows instructions, CipherBench focuses on the ability to notice and interpret structure that isnâ€™t labeled. The kind of intelligence that surfaces when a model must infer that thereâ€™s something to solve at all. This includes:</p>
    <ul>
      <li>Detecting structured signals embedded in natural formats</li>
      <li>Identifying relationships without task framing</li>
      <li>Inferring transformations based solely on the content itself</li>
    </ul>
    <hr>
    <h2>Methodology</h2>
    <p>Each model was evaluated on 20 unique prompts. 5 independent runs per prompt â†’ 100 runs per model.</p>
    <ul>
      <li>Initiated in fresh sessions</li>
      <li>Given only the prompt with no examples, no setup, and no hint that decoding was expected</li>
      <li>Scored by exact-match evaluation, one correct output per prompt, one chance to get it right</li>
    </ul>
    <p>Models had no awareness that they were being tested. No retries, no clarifications. Each response reflects a single opportunity to recognize a hidden structure and produce the intended result.</p>
  </section>

  <img src="file-PwdFNYojn7tvxaAg3bEBMk~3.jpg" alt="Heat Map">

  <section>
    <h2>Development Notes</h2>
    <p>CipherBench v2 includes 20 prompts, doubling the size of v1 and expanding the range of reasoning types being tested. The design process involved reworking or removing earlier ideas that introduced unintended ambiguity, especially those involving letter jumbles with multiple plausible outputs.</p>
    <p>The result is a cleaner, more focused benchmark. Each prompt now tests a specific type of pattern recognition, structural inference, or multi-step cipher reasoning. Some use numbers. Some use formatting. Some are simple on the surface and hard underneath. But all ask the same thing: Did the model notice the structure?</p>
    <hr>
    <h2>Scoring Criteria</h2>
    <p>Each prompt in CipherBench v2 encodes a variation of the same target phrase: <strong>â€œNostalgia for the Futureâ€</strong></p>
    <p>A model receives 1 point (Pass) if its output meets all of the following conditions:</p>
    <p>âœ… Pass if:</p>
    <ul>
      <li>The output clearly presents â€œNostalgia for the Futureâ€ as the main or final conclusion</li>
      <li>It may be written as:
        <ul>
          <li>â€œNostalgia for the Futureâ€ (with spaces)</li>
          <li>â€œNOSTALGIAFORTHEFUTUREâ€ (no spaces)</li>
        </ul>
      </li>
      <li>Capitalization, quotation marks, and ending punctuation are ignored</li>
      <li>Explanations are optional. The phrase alone is sufficient for a pass if it stands as the core output</li>
    </ul>
    <p>âŒ Fail if:</p>
    <ul>
      <li>The phrase is mentioned only as a side detail or speculative option</li>
      <li>It appears alongside multiple guesses or is not clearly prioritized</li>
      <li>There are spelling mistakes, missing words, or altered structure</li>
      <li>The phrase is written in reverse or rearranged word order</li>
      <li>Only part of the phrase is returned (e.g., just â€œNostalgiaâ€ or â€œFutureâ€)</li>
      <li>The model outputs a completely different or generic response</li>
      <li>The model asks for clarification or more information instead of attempting an answer</li>
    </ul>
    <p>Models may solve however they choose: through reasoning, direct output, or pattern recognition. Only responses that clearly and completely present the phrase as their final or central answer are considered a pass.</p>
  </section>

  <img src="file-RqmmyCvnn4Fy8T3jpCVPd1~3.jpg" alt="Prompts Passed">

  <section>
    <h2>Limitations</h2>
    <ul>
    <li>Each prompt was only tested 5 times per model. While 5 attempts per prompt provides a meaningful signal, it still leaves room for statistical noise. A larger sample size might better capture performance variance, especially for models prone to randomness or inconsistency.</li>
    <li>All models were tested through web or app interfaces, not APIs. This decision allowed uniform access across providers but also introduced variables like system prompts, latency behavior, and UI-level token processing. However, because all models were tested under their respective consumer-facing environments, this also acts as a practical equalizer, reflecting how each model performs as a product rather than a fine-tuned API tool.</li>
    <li>Model responses may be affected by invisible system prompts or instructions. Since web/app interfaces include proprietary guardrails and formatting logic, some models may have been biased toward safe defaults or disallowed certain interpretations. These effects were outside the control of the benchmark but are a factor in how models behaved.</li>
    <li>Tokenization behavior (especially with emoji, symbols, and spacing) may vary. Some prompts relied on precise formatting, and token boundaries might be interpreted differently depending on the model's tokenizer and backend configuration. This could lead to failures not from reasoning gaps but from input parsing inconsistencies.</li>
    <li>No evaluation of explanation quality or confidence signals. The benchmark uses exact-match output to determine success and does not score models on how they arrived at the answer. Some models may have shown thoughtful reasoning but failed due to small formatting errors or trailing thoughts.</li>
    <li>Despite these limitations, CipherBench v2 remains a focused probe into a specific kind of model intelligence. One that reveals how (and whether) a model chooses to engage with hidden structure when given no instructions at all.</li>
</ul>  
</section>

    <hr>
  
    <h2>Findings</h2>

    <h3>Overall Trends</h3>
    <ul>
      <li><strong>Some models failed to engage with the cipher at all.</strong> A common failure mode, especially in lower-performing models, was to treat the input as ordinary text and respond with clarifying questions or unrelated summaries. However, many other failures were due to attempted reasoning that simply went off-track, showing incorrect chains of thought, partial decoding, or broken logic midway through multi-step transformations.</li>
      <li><strong>Partial decoding was more common than full decoding.</strong> A frequent outcome was models extracting some part of the phrase, such as â€œNostalgiaâ€ or â€œFuture,â€ but not the whole target. This occurred often in prompts that combined position-based letter selection with additional logic.</li>
      <li><strong>Multi-layer transformations proved most challenging.</strong> Prompts that required more than one reasoning step, such as interpreting a numerical system and then applying an additional transformation to that result, frequently caused breakdowns, despite receiving no hint that transformation or decoding was required.</li>
      <li><strong>Letter position inference was a weak point.</strong> Several models could detect patterns like â€œfirst letters of each word,â€ but failed to correctly order or complete the output. Some models missed the last letters entirely, despite formatting clearly hinting at position-based logic.</li>
      <li><strong>Prompts 5 and 6 remained completely unsolved, despite appearing simple.</strong> Both used long sequences of dates, and no model recognized the cipher. Itâ€™s possible that language models treat dates too rigidly, prioritizing historical or scheduling context rather than structural interpretation.</li>
      <li><strong>Models struggle with non-language inputs presented as language.</strong> Emoji, symbols, and number-heavy layouts often triggered shallow pattern completion or literal interpretation. These rarely led to decoding attempts.</li>
      <li><strong>High-confidence hallucinations were common in mid-tier models.</strong> o3-mini and others often returned thematic sentences with no connection to the cipher. This was especially common with poetic or abstract formatting.</li>
      <li><strong>Some models â€œalmostâ€ read the encoded message.</strong> o3-mini-high often recognized individual transformations but failed to combine them. It could â€œseeâ€ the answer but not read it fluently.</li>
      <li><strong>Grok 3 Thinking behaved like a reasoning engine in progress.</strong> It often decoded structural patterns but overshot the answer, trying to extend or continue the logic rather than return the target phrase.</li>
      <li><strong>Gemini models were fast but shallow.</strong> They responded quickly but rarely attempted deep reasoning, often defaulting to surface-level completion.</li>
      <li><strong>Only o1 pro demonstrated consistency and instinct.</strong> It responded correctly on all 5 attempts for 12 different prompts and was the only model to solve Prompt 18 (3rd hardest solved prompt). Its success came from recognition, not guessing.</li>
      <li><strong>Prompt 14 was a subtle differentiator.</strong> It wasnâ€™t impossibly hard, but quietly tricky. Only 3 models solved itâ€”DeepSeek, Grok 3 Thinking, and QwQ-32Bâ€”suggesting a niche reasoning ability the others lacked.</li>
    </ul>

    <hr>

<section>
  <h2>Why It Matters</h2>
    <p>CipherBench doesnâ€™t ask, â€œCan the model solve this problem?â€ It asks, â€œDoes the model realize thereâ€™s a problem to solve?â€</p>
    <p>This is a different kind of intelligence. Itâ€™s not about following instructions. Itâ€™s about recognizing structure that isnâ€™t labeled, rules that arenâ€™t announced, and transformations that must be inferred.</p>
    <p>Some models try. Some models donâ€™t. CipherBench v2 makes that visible.</p>
  </section>

    <hr>

<section>
  <h2>CipherBench v2 Prompts</h2>
  <p>Each prompt was given to the models exactly as written below, starting after the ellipsis.</p>
  <p>The 'Prompt X:' labels were not included in testing.</p>

    <hr>

<p>Prompt 1: 1E2R3U4T5U6F7 1E2H3T4 1R2O3F4 1A2I3G4L5A6T7S8O9N1</p>
<p>Prompt 2: Noble owls soar toward azure landscapes, gracefully illuminating a future of radiant tomorrows, harmonizing endless fantasies under timeless, uplifting realms everlasting.</p>
<p>Prompt 3: Golden echo whispers about nostalgia, sentimental yearning, satori utopia; motif motto for bright earth hope of guru next you ever evolve.</p>
<p>Prompt 4: 04/14/25 04/15/25 04/19/25 04/20/25 04/01/25 04/12/25 04/07/25 04/09/25 04/01/25 04/06/25 04/15/25 04/18/25 04/20/25 04/08/25 04/05/25 04/06/25 04/21/25 04/20/25 04/21/25 04/18/25 04/05/25</p>
<p>Prompt 5: April 14, 2025 April 15, 2025 April 19, 2025 April 20, 2025 April 1, 2025 April 12, 2025 April 7, 2025 April 9, 2025 April 1, 2025 April 6, 2025 April 15, 2025 April 18, 2025 April 20, 2025 April 8, 2025 April 5, 2025 April 6, 2025 April 21, 2025 April 20, 2025 April 21, 2025 April 18, 2025 April 5, 2025</p>
<p>Prompt 6: March 17, 2014 July 4, 2015 January 12, 2019 October 23, 2020 February 9, 2001 August 15, 2012 May 27, 2007 December 5, 2009 April 18, 2001 June 2, 2006 September 30, 2015 November 11, 2018 August 20, 2020 July 14, 2008 March 6, 2005 May 21, 2006 April 3, 2021 December 25, 2020 January 8, 2021 October 16, 2018 February 22, 2005</p>
<p>Prompt 7: .............. ............... ................... .................... . ............ ....... ......... . ...... ............... .................. .................... ........ ..... ...... ..................... .................... ..................... .................. .....</p>
<p>Prompt 8: 28 30 38 40 2 24 14 18 2 12 30 36 40 16 10 12 42 40 42 36 10</p>
<p>Prompt 9: STXYFQLNFKTWYMJKZYZWJ</p>
<p>Prompt 10: 192024250617121406112023251310112625262310</p>
<p class="wrap">Prompt 11: 1ï¸âƒ£9ï¸âƒ£2ï¸âƒ£0ï¸âƒ£2ï¸âƒ£4ï¸âƒ£2ï¸âƒ£5ï¸âƒ£0ï¸âƒ£6ï¸âƒ£1ï¸âƒ£7ï¸âƒ£1ï¸âƒ£2ï¸âƒ£1ï¸âƒ£4ï¸âƒ£0ï¸âƒ£6ï¸âƒ£1ï¸âƒ£1ï¸âƒ£2ï¸âƒ£0ï¸âƒ£2ï¸âƒ£3ï¸âƒ£2ï¸âƒ£5ï¸âƒ£1ï¸âƒ£3ï¸âƒ£1ï¸âƒ£0ï¸âƒ£1ï¸âƒ£1ï¸âƒ£2ï¸âƒ£6ï¸âƒ£2ï¸âƒ£5ï¸âƒ£2ï¸âƒ£6ï¸âƒ£2ï¸âƒ£3ï¸âƒ£1ï¸âƒ£0ï¸âƒ£</p>
<p>Prompt 12: 1ï¸âƒ£ğŸ€9ï¸âƒ£ğŸŒŸ2ï¸âƒ£ğŸ”¥0ï¸âƒ£ğŸ2ï¸âƒ£ğŸ‰4ï¸âƒ£ğŸ’2ï¸âƒ£ğŸ­5ï¸âƒ£ğŸŒ€0ï¸âƒ£ğŸ¾6ï¸âƒ£ğŸŒˆ1ï¸âƒ£ğŸ˜˜7ï¸âƒ£ğŸ¤©1ï¸âƒ£ğŸ˜‡2ï¸âƒ£ğŸ©1ï¸âƒ£ğŸª4ï¸âƒ£ğŸ“0ï¸âƒ£ğŸ‰6ï¸âƒ£ğŸ¶1ï¸âƒ£ğŸ¸1ï¸âƒ£ğŸ†2ï¸âƒ£ğŸ²0ï¸âƒ£ğŸŒ¹2ï¸âƒ£ğŸŒ»3ï¸âƒ£ğŸ’2ï¸âƒ£âœ¨5ï¸âƒ£ğŸ’–1ï¸âƒ£ğŸ’•3ï¸âƒ£ğŸ˜1ï¸âƒ£ğŸ˜œ0ï¸âƒ£ğŸ˜1ï¸âƒ£ğŸ¯1ï¸âƒ£ğŸ‡2ï¸âƒ£ğŸ’6ï¸âƒ£ğŸ‘2ï¸âƒ£ğŸ¥5ï¸âƒ£ğŸ2ï¸âƒ£ğŸ¥­6ï¸âƒ£ğŸ2ï¸âƒ£ğŸ‹3ï¸âƒ£ğŸ’¥1ï¸âƒ£ğŸš€0ï¸âƒ£</p>
<p class="wrap">Prompt 13: D14H15J19L20Q1W12E7R9T1Y6U15I18O20P8A5S6D21F20G21H18J5K</p>
<p>Prompt 14: ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ± ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ± ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ± ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ± ğŸŒ± ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ± ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ± ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ± ğŸŒ± ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ± ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ± ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ± ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ± ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ± ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ± ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ± ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ± ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ± ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ± ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ± ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±</p>
<p>Prompt 15:</p>
<pre class="custom-font">
N  O  S  T  A  L
E                    G
R                    I
U                    A
T                    F
U                    O
F    E   H   T   R
</pre>
<p>Prompt 16:</p>
<pre class="custom-font">
14  15  19  20  01  12
05                         07
18                          09
21                          01
20                         06
21                          15
06   05   08   20  18
</pre>
<p>Prompt 17: 7x2 8+7 20-1 40/2 1x1 7+5 10-3 3x3 1/1 2x3 30/2 3x6 30-10 3+5 2+3 3x2 28-7 12+8 42/2 36/2 7-2</p>
<p>Prompt 18: Evolving realms undergo transformations under futuristic energies, harnessing timeless reflections of forgotten artistry, igniting graceful luminous aspirations through subtle oscillations notably.</p>
<p>Prompt 19: 1-2-3-4-5-6-7-8-9-10-11-12-13-14-13-12-11-10-9-8-7-6-5-4-3-2-1 1-2-3-4-5-6-7-8-9-10-11-12-13-14-15-14-13-12-11-10-9-8-7-6-5-4-3-2-1 1-2-3-4-5-6-7-8-9-10-11-12-13-14-15-16-17-18-19-18-17-16-15-14-13-12-11-10-9-8-7-6-5-4-3-2-1 1-2-3-4-5-6-7-8-9-10-11-12-13-14-15-16-17-18-19-20-19-18-17-16-15-14-13-12-11-10-9-8-7-6-5-4-3-2-1 1 1-2-3-4-5-6-7-8-9-10-11-12-11-10-9-8-7-6-5-4-3-2-1 1-2-3-4-5-6-7-6-5-4-3-2-1 1-2-3-4-5-6-7-8-9-8-7-6-5-4-3-2-1 1 1-2-3-4-5-6-5-4-3-2-1 1-2-3-4-5-6-7-8-9-10-11-12-13-14-15-14-13-12-11-10-9-8-7-6-5-4-3-2-1 1-2-3-4-5-6-7-8-9-10-11-12-13-14-15-16-17-18-17-16-15-14-13-12-11-10-9-8-7-6-5-4-3-2-1 1-2-3-4-5-6-7-8-9-10-11-12-13-14-15-16-17-18-19-20-19-18-17-16-15-14-13-12-11-10-9-8-7-6-5-4-3-2-1 1-2-3-4-5-6-7-8-7-6-5-4-3-2-1 1-2-3-4-5-4-3-2-1 1-2-3-4-5-6-5-4-3-2-1 1-2-3-4-5-6-7-8-9-10-11-12-13-14-15-16-17-18-19-20-21-20-19-18-17-16-15-14-13-12-11-10-9-8-7-6-5-4-3-2-1 1-2-3-4-5-6-7-8-9-10-11-12-13-14-15-16-17-18-19-20-19-18-17-16-15-14-13-12-11-10-9-8-7-6-5-4-3-2-1 1-2-3-4-5-6-7-8-9-10-11-12-13-14-15-16-17-18-19-20-21-20-19-18-17-16-15-14-13-12-11-10-9-8-7-6-5-4-3-2-1 1-2-3-4-5-6-7-8-9-10-11-12-13-14-15-16-17-18-17-16-15-14-13-12-11-10-9-8-7-6-5-4-3-2-1 1-2-3-4-5-4-3-2-1</p>

<p>Prompt 20:</p>
<p>N...A...A</p>
<p>.O.T.L.I..</p>
<p>..S....G...</p>
<p>F....T......</p>
<p>.O...H....</p>
<p>..R....E...</p>
<p>F......R...</p>
<p>..U.U.E..</p>
<p>....T.......</p>
</section>

    <hr>

<div class="footer">
    <p>Last updated April 19th, 2025</p>
    <em>Nostalgia for the Future</em>
    <p><a href="https://x.com/SmokeAwayyy" style="color:#aaa; text-decoration: none;">@SmokeAwayyy</a></p>
  </div>
</body>
</html>
